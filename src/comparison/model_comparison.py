#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import time
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.models.hmm_ner import HMMNER
from src.models.crf_ner import CRFNER
from src.visualization.visualization import HMMVisualization

class ModelComparison:
    """æ¨¡å‹å¯¹æ¯”ç±»"""
    
    def __init__(self):
        self.hmm_model = HMMNER()
        self.crf_model = CRFNER(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100)
        self.viz = HMMVisualization()
        
        # ç»“æœå­˜å‚¨
        self.results = {}
        
    def load_and_prepare_data(self, data_file):
        """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
        print("=" * 60)
        print("æ•°æ®åŠ è½½å’Œå‡†å¤‡")
        print("=" * 60)
        
        # åŠ è½½æ•°æ®
        sequences, labels = self.hmm_model.load_data(data_file)
        
        # æ„å»ºè¯æ±‡è¡¨
        self.hmm_model.build_vocabulary(sequences, min_freq=2)
        self.crf_model.build_vocabulary(sequences, min_freq=2)
        
        # åˆ’åˆ†æ•°æ®é›†
        train_seqs, test_seqs, train_labels, test_labels = train_test_split(
            sequences, labels, test_size=0.2, random_state=42
        )
        
        print(f"è®­ç»ƒé›†å¤§å°: {len(train_seqs)}")
        print(f"æµ‹è¯•é›†å¤§å°: {len(test_seqs)}")
        
        return train_seqs, test_seqs, train_labels, test_labels
    
    def train_hmm_model(self, train_seqs, train_labels):
        """è®­ç»ƒHMMæ¨¡å‹"""
        print("\n" + "=" * 60)
        print("è®­ç»ƒHMMæ¨¡å‹")
        print("=" * 60)
        
        start_time = time.time()
        self.hmm_model.train(train_seqs, train_labels)
        hmm_train_time = time.time() - start_time
        
        print(f"HMMè®­ç»ƒæ—¶é—´: {hmm_train_time:.2f}ç§’")
        
        return hmm_train_time
    
    def train_crf_model(self, train_seqs, train_labels):
        """è®­ç»ƒCRFæ¨¡å‹"""
        print("\n" + "=" * 60)
        print("è®­ç»ƒCRFæ¨¡å‹")
        print("=" * 60)
        
        start_time = time.time()
        self.crf_model.train(train_seqs, train_labels)
        crf_train_time = time.time() - start_time
        
        print(f"CRFè®­ç»ƒæ—¶é—´: {crf_train_time:.2f}ç§’")
        
        return crf_train_time
    
    def evaluate_models(self, test_seqs, test_labels):
        """è¯„ä¼°ä¸¤ä¸ªæ¨¡å‹"""
        print("\n" + "=" * 60)
        print("æ¨¡å‹è¯„ä¼°")
        print("=" * 60)
        
        # HMMé¢„æµ‹å’Œè¯„ä¼°
        print("\n--- HMMæ¨¡å‹è¯„ä¼° ---")
        start_time = time.time()
        hmm_pred_labels = self.hmm_model.predict(test_seqs)
        hmm_pred_time = time.time() - start_time
        
        hmm_report = self.hmm_model.evaluate(test_labels, hmm_pred_labels)
        
        # CRFé¢„æµ‹å’Œè¯„ä¼°
        print("\n--- CRFæ¨¡å‹è¯„ä¼° ---")
        start_time = time.time()
        crf_pred_labels = self.crf_model.predict(test_seqs)
        crf_pred_time = time.time() - start_time
        
        crf_report, crf_f1 = self.crf_model.evaluate(test_labels, crf_pred_labels)
        
        # å­˜å‚¨ç»“æœ
        self.results = {
            'hmm': {
                'pred_labels': hmm_pred_labels,
                'report': hmm_report,
                'pred_time': hmm_pred_time
            },
            'crf': {
                'pred_labels': crf_pred_labels,
                'report': crf_report,
                'f1_score': crf_f1,
                'pred_time': crf_pred_time
            },
            'test_labels': test_labels,
            'test_seqs': test_seqs
        }
        
        return hmm_pred_time, crf_pred_time
    
    def compare_performance(self):
        """æ¯”è¾ƒæ¨¡å‹æ€§èƒ½"""
        print("\n" + "=" * 60)
        print("æ€§èƒ½å¯¹æ¯”")
        print("=" * 60)
        
        # è®¡ç®—HMMçš„F1åˆ†æ•°
        flat_true = []
        flat_hmm_pred = []
        
        for true_seq, pred_seq in zip(self.results['test_labels'], self.results['hmm']['pred_labels']):
            min_len = min(len(true_seq), len(pred_seq))
            flat_true.extend(true_seq[:min_len])
            flat_hmm_pred.extend(pred_seq[:min_len])
        
        hmm_f1 = f1_score(flat_true, flat_hmm_pred, average='weighted')
        
        # è·å–CRFçš„F1åˆ†æ•°
        crf_f1 = self.results['crf']['f1_score']
        
        # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
        comparison_data = {
            'æŒ‡æ ‡': ['F1åˆ†æ•°', 'é¢„æµ‹æ—¶é—´(ç§’)', 'æ¨¡å‹å¤æ‚åº¦'],
            'HMM': [f'{hmm_f1:.4f}', f'{self.results["hmm"]["pred_time"]:.2f}', 'ä½'],
            'CRF': [f'{crf_f1:.4f}', f'{self.results["crf"]["pred_time"]:.2f}', 'é«˜']
        }
        
        df = pd.DataFrame(comparison_data)
        print("\næ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
        print(df.to_string(index=False))
        
        # åˆ¤æ–­å“ªä¸ªæ¨¡å‹æ›´å¥½
        if hmm_f1 > crf_f1:
            print(f"\nğŸ† HMMæ¨¡å‹è¡¨ç°æ›´å¥½ (F1: {hmm_f1:.4f} vs {crf_f1:.4f})")
        elif crf_f1 > hmm_f1:
            print(f"\nğŸ† CRFæ¨¡å‹è¡¨ç°æ›´å¥½ (F1: {crf_f1:.4f} vs {hmm_f1:.4f})")
        else:
            print(f"\nğŸ¤ ä¸¤ä¸ªæ¨¡å‹è¡¨ç°ç›¸å½“ (F1: {hmm_f1:.4f})")
        
        return hmm_f1, crf_f1
    
    def create_comparison_visualizations(self):
        """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–"""
        print("\n" + "=" * 60)
        print("åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–")
        print("=" * 60)
        
        os.makedirs('comparison_results', exist_ok=True)
        
        # 1. F1åˆ†æ•°å¯¹æ¯”
        hmm_f1, crf_f1 = self.compare_performance()
        
        plt.figure(figsize=(10, 6))
        models = ['HMM', 'CRF']
        f1_scores = [hmm_f1, crf_f1]
        colors = ['#FF6B6B', '#4ECDC4']
        
        bars = plt.bar(models, f1_scores, color=colors, alpha=0.7)
        plt.title('HMM vs CRF F1åˆ†æ•°å¯¹æ¯”', fontsize=16, fontweight='bold')
        plt.ylabel('F1åˆ†æ•°', fontsize=12)
        plt.ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars, f1_scores):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{score:.4f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('comparison_results/f1_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 2. é¢„æµ‹æ—¶é—´å¯¹æ¯”
        hmm_time = self.results['hmm']['pred_time']
        crf_time = self.results['crf']['pred_time']
        
        plt.figure(figsize=(10, 6))
        times = [hmm_time, crf_time]
        
        bars = plt.bar(models, times, color=colors, alpha=0.7)
        plt.title('HMM vs CRF é¢„æµ‹æ—¶é—´å¯¹æ¯”', fontsize=16, fontweight='bold')
        plt.ylabel('é¢„æµ‹æ—¶é—´ (ç§’)', fontsize=12)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, time_val in zip(bars, times):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{time_val:.2f}s', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('comparison_results/time_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 3. æ··æ·†çŸ©é˜µå¯¹æ¯”
        flat_true = []
        flat_hmm_pred = []
        flat_crf_pred = []
        
        for true_seq, hmm_pred, crf_pred in zip(
            self.results['test_labels'], 
            self.results['hmm']['pred_labels'], 
            self.results['crf']['pred_labels']
        ):
            min_len = min(len(true_seq), len(hmm_pred), len(crf_pred))
            flat_true.extend(true_seq[:min_len])
            flat_hmm_pred.extend(hmm_pred[:min_len])
            flat_crf_pred.extend(crf_pred[:min_len])
        
        # HMMæ··æ·†çŸ©é˜µ
        self.viz.plot_confusion_matrix(
            flat_true, flat_hmm_pred, self.hmm_model.states,
            'comparison_results/hmm_confusion_matrix.png'
        )
        
        # CRFæ··æ·†çŸ©é˜µ
        self.viz.plot_confusion_matrix(
            flat_true, flat_crf_pred, self.crf_model.states,
            'comparison_results/crf_confusion_matrix.png'
        )
    
    def save_comparison_results(self):
        """ä¿å­˜å¯¹æ¯”ç»“æœ"""
        print("\n" + "=" * 60)
        print("ä¿å­˜å¯¹æ¯”ç»“æœ")
        print("=" * 60)
        
        # ä¿å­˜æ¨¡å‹
        self.hmm_model.save_model('comparison_results/hmm_model.pkl')
        self.crf_model.save_model('comparison_results/crf_model.pkl')
        
        # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
        hmm_f1, crf_f1 = self.compare_performance()
        
        comparison_report = f"""
HMM vs CRF æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š
======================

æ•°æ®é›†ä¿¡æ¯:
- è®­ç»ƒé›†å¤§å°: {len(self.results['test_seqs'])}
- æµ‹è¯•é›†å¤§å°: {len(self.results['test_labels'])}
- å®ä½“ç±»å‹: {len(self.hmm_model.states)} ç§

æ¨¡å‹æ€§èƒ½å¯¹æ¯”:
- HMM F1åˆ†æ•°: {hmm_f1:.4f}
- CRF F1åˆ†æ•°: {crf_f1:.4f}
- HMMé¢„æµ‹æ—¶é—´: {self.results['hmm']['pred_time']:.2f}ç§’
- CRFé¢„æµ‹æ—¶é—´: {self.results['crf']['pred_time']:.2f}ç§’

æ¨¡å‹ç‰¹ç‚¹:
HMM:
- ä¼˜ç‚¹: è®­ç»ƒé€Ÿåº¦å¿«ï¼Œæ¨¡å‹ç®€å•
- ç¼ºç‚¹: å‡è®¾è§‚æµ‹ç‹¬ç«‹æ€§ï¼Œç‰¹å¾è¡¨è¾¾èƒ½åŠ›æœ‰é™

CRF:
- ä¼˜ç‚¹: ç‰¹å¾è¡¨è¾¾èƒ½åŠ›å¼ºï¼Œè€ƒè™‘æ ‡ç­¾é—´ä¾èµ–å…³ç³»
- ç¼ºç‚¹: è®­ç»ƒæ—¶é—´é•¿ï¼Œæ¨¡å‹å¤æ‚

ç»“è®º:
{'HMMæ¨¡å‹è¡¨ç°æ›´å¥½' if hmm_f1 > crf_f1 else 'CRFæ¨¡å‹è¡¨ç°æ›´å¥½' if crf_f1 > hmm_f1 else 'ä¸¤ä¸ªæ¨¡å‹è¡¨ç°ç›¸å½“'}
"""
        
        with open('comparison_results/comparison_report.txt', 'w', encoding='utf-8') as f:
            f.write(comparison_report)
        
        print("å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ° comparison_results/ ç›®å½•")
    
    def run_complete_comparison(self, data_file='data/ccfbdci.jsonl'):
        """è¿è¡Œå®Œæ•´çš„æ¨¡å‹å¯¹æ¯”"""
        print("ğŸš€ å¼€å§‹HMM vs CRFæ¨¡å‹å¯¹æ¯”")
        
        # 1. æ•°æ®å‡†å¤‡
        train_seqs, test_seqs, train_labels, test_labels = self.load_and_prepare_data(data_file)
        
        # 2. è®­ç»ƒæ¨¡å‹
        hmm_train_time = self.train_hmm_model(train_seqs, train_labels)
        crf_train_time = self.train_crf_model(train_seqs, train_labels)
        
        # 3. è¯„ä¼°æ¨¡å‹
        hmm_pred_time, crf_pred_time = self.evaluate_models(test_seqs, test_labels)
        
        # 4. æ€§èƒ½å¯¹æ¯”
        self.compare_performance()
        
        # 5. åˆ›å»ºå¯è§†åŒ–
        self.create_comparison_visualizations()
        
        # 6. ä¿å­˜ç»“æœ
        self.save_comparison_results()
        
        print("\nğŸ‰ æ¨¡å‹å¯¹æ¯”å®Œæˆ!")
        print("ç»“æœæ–‡ä»¶ä¿å­˜åœ¨ comparison_results/ ç›®å½•")

def main():
    """ä¸»å‡½æ•°"""
    comparison = ModelComparison()
    comparison.run_complete_comparison()

if __name__ == "__main__":
    main() 